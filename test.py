# -*- coding: utf-8 -*-
"""TD3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C0DzbWpB9a1Ci_Pw1kGFHXDMEddB4KsB

# Twin Delayed Deep Deterministic Policy Gradient (TD3)

# Setup
"""

# pip install tensorboardX
# pip install gym
# pip install roboschool

"""# Imports"""

import numpy as np
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.nn.functional as F
from tensorboardX import SummaryWriter

import gym
#import roboschool
import sys
import argparse

from components import TD3, ReplayBuffer, Runner

def hidden_init(layer):
    fan_in = layer.weight.data.size()[0]
    lim = 1. / np.sqrt(fan_in)
    return (-lim, lim)

"""# Evaluate"""

def evaluate_policy(policy, env, eval_episodes=100,render=False):
    """run several episodes using the best agent policy
        
        Args:
            policy (agent): agent to evaluate
            env (env): gym environment
            eval_episodes (int): how many test episodes to run
            render (bool): show training
        
        Returns:
            avg_reward (float): average reward over the number of evaluations
    
    """
    
    avg_reward = 0.
    for i in range(eval_episodes):
        obs = env.reset()
        done = False
        while not done:
            if render:
                env.render()
            action = policy.select_action(np.array(obs), noise=0)
            obs, reward, done, _ = env.step(action)
            avg_reward += reward

    avg_reward /= eval_episodes

    print("\n---------------------------------------")
    print("Evaluation over {:d} episodes: {:f}" .format(eval_episodes, avg_reward))
    print("---------------------------------------")
    return avg_reward

"""# Config"""

ENV = "gym_drone:drone-v0" #"Pendulum-v0" #"RoboschoolHalfCheetah-v1"
SEED = 0
OBSERVATION = 10000
EXPLORATION = 5000000
BATCH_SIZE = 100
GAMMA = 0.99
TAU = 0.005
NOISE = 0.2
NOISE_CLIP = 0.5
EXPLORE_NOISE = 0.1
POLICY_FREQUENCY = 2
EVAL_FREQUENCY = 10000
REWARD_THRESH = 1000

"""# Main"""
def main(args):
    env = gym.make(ENV)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Set seeds
    env.seed(SEED)
    torch.manual_seed(SEED)
    np.random.seed(SEED)

    state_dim = env.observation_space.shape[0]
    action_dim = env.action_space.shape[0] 
    min_action = float(env.action_space.low[0])
    max_action = float(env.action_space.high[0])

    print("Initializing...")
    print("State dim: {}, Action dim: {}, Min action: {}, Max action: {}".format(state_dim, action_dim, min_action, max_action))

    policy = TD3(state_dim, action_dim, (min_action, max_action), env, device)

    policy.load(suffix=args.save_index)

    for i in range(100):
        evaluate_policy(policy, env, render=True)

    env.close()

def parse_args():
    parser = argparse.ArgumentParser(description="TD3 Drone Flight Trainer")
    parser.add_argument("--save_index", help="Allows for multiple simultaneous runs ('-1' e.g.)", default="")
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_args()
    main(args)

