# -*- coding: utf-8 -*-
"""TD3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C0DzbWpB9a1Ci_Pw1kGFHXDMEddB4KsB

# Twin Delayed Deep Deterministic Policy Gradient (TD3)

# Setup
"""

# pip install tensorboardX
# pip install gym
# pip install roboschool

"""# Imports"""

import numpy as np
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.nn.functional as F
from tensorboardX import SummaryWriter

import gym
#import roboschool
import sys
import argparse

from components import TD3, ReplayBuffer, Runner
from controller import Controller_PID_Point2Point
# def hidden_init(layer):
#     fan_in = layer.weight.data.size()[0]
#     lim = 1. / np.sqrt(fan_in)
#     return (-lim, lim)

"""# Evaluate"""

def evaluate_controller(controller, env, eval_episodes=200,render=False):
    """run several episodes using the best agent policy
        
        Args:
            policy (agent): agent to evaluate
            env (env): gym environment
            eval_episodes (int): how many test episodes to run
            render (bool): show training
        
        Returns:
            avg_reward (float): average reward over the number of evaluations
    
    """
    
    avg_reward = 0.
    for i in range(eval_episodes):
        obs = env.reset()
        done = False
        while not done:
            if render:
                env.render()
            action = controller.update(np.array(obs))
            obs, reward, done, _ = env.step(action)
            avg_reward += reward
        
        print("\rEpisode Num: {:d} Reward: {:f} Avg Reward: {:f}".format(
            i, reward, avg_reward / float(i + 1)), end="")
        sys.stdout.flush()

    avg_reward /= eval_episodes

    print("\n---------------------------------------")
    print("Evaluation over {:d} episodes: {:f}" .format(eval_episodes, avg_reward))
    print("---------------------------------------")
    return avg_reward

"""# Config"""

ENV = "gym_drone:drone-v0" #"Pendulum-v0" #"RoboschoolHalfCheetah-v1"
SEED = 0
OBSERVATION = 10000
EXPLORATION = 5000000
BATCH_SIZE = 100
GAMMA = 0.99
TAU = 0.005
NOISE = 0.2
NOISE_CLIP = 0.5
EXPLORE_NOISE = 0.1
POLICY_FREQUENCY = 2
EVAL_FREQUENCY = 10000
REWARD_THRESH = 1000

"""# Main"""
def main(args):
    env = gym.make(ENV)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Set seeds
    env.seed(SEED)
    torch.manual_seed(SEED)
    np.random.seed(SEED)

    state_dim = env.observation_space.shape[0]
    action_dim = env.action_space.shape[0] 
    min_action = float(env.action_space.low[0])
    max_action = float(env.action_space.high[0])

    print("Initializing...")
    print("State dim: {}, Action dim: {}, Min action: {}, Max action: {}".format(state_dim, action_dim, min_action, max_action))

    # policy = TD3(state_dim, action_dim, (min_action, max_action), env, device)

    # policy.load(suffix=args.save_index)

    controller = Controller_PID_Point2Point()

    for i in range(100):
        evaluate_controller(controller, env, render=args.render)

    env.close()

def parse_args():
    parser = argparse.ArgumentParser(description="TD3 Drone Flight Trainer")
    render_parser = parser.add_mutually_exclusive_group(required=False)
    render_parser.add_argument("--render", help="Shows visual representation of Drone Environment", dest="render", action="store_true")
    render_parser.add_argument("--no-render", help="Prevents visual representation of Drone Environment", dest="render", action="store_false")
    parser.set_defaults(render=False)
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_args()
    main(args)

